= Unstructured Documents Processing with dbt Projects
:toc:
:toc-placement!:

toc::[]


== Overview

This page describes the use of link:https://docs.snowflake.com/en/sql-reference/functions/ai_parse_document.html[AI_PARSE_DOCUMENT]  to extract text chunks from documents and link:https://docs.snowflake.com/en/sql-reference/functions/ai_extract.html[AI_EXTRACT] to extract question and answer pairs from documents.


== Approach

=== Triggered Document Processing
It starts with a View in Bronze that contains the newly ingested raw documents (newly added to the `documents_stream` table). The documents are expected to land (in staging) in either one of the following directories to be processed in a certain way:

* `@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS/full` - for full documents that are not expected to be split into chunks
* `@INCIDENT_MANAGEMENT.bronze_zone.DOCUMENTS/qa` - for documents that are expected to be split into chunks for question and answer extraction

==== Chunk Extraction for Cortex Search

For Cortex Search, we need to extract the text chunks from the documents and hence the documents under _full_ sub-directory are then picked up by the dbt model link:../src/incident_management/models/silver_zone/document_full_extracts.sql[`document_full_extracts`] in Silver Zone. This model is tagged as 'document_processing' to indicate that it is a document processing model and is going to run through a link:https://docs.snowflake.com/en/user-guide/tasks-triggered[Triggered Task] whenever there is a new document added to the _full_ sub-directory.

==== Question and Answer Extraction

The documents under _qa_ sub-directory are picked up by the dbt model link:../src/incident_management/models/silver_zone/document_question_extracts.py[`document_question_extracts`] in Silver Zone. 
This model is also tagged as 'document_processing' to indicate that it is a document processing model and is going to run through a link:https://docs.snowflake.com/en/user-guide/tasks-triggered[Triggered Task] whenever there is a new document added to the _qa_ sub-directory.

In order to provide the questions that will be used with the AI_EXTRACT function, the model uses the `meta` configuration in the model YAML file to define the questions that will be used with the AI_EXTRACT function.

The `meta` configuration is defined in the dbt model link:../src/incident_management/models/silver_zone/document_question_extracts.yml[`document_question_extracts.yml`] in Silver Zone. It is a dictionary that contains the questions that will be used with the AI_EXTRACT function. The specific set of questions you will find is under the `quaterly_review_metrics` key, written for a quarterly review metrics reports (sample document: link:../data/docs/qa/incm_quaterly_review_metrics_2025_Q2.pdf[incm_quaterly_review_metrics_2025_Q2.pdf]).

You can use this pattern to define the questions for any other type of document processing that you may need. The structure that you can use for each document type can be of the form:
[source,yaml]
----
meta:   
    <document_type>:
        enabled: true
        schema:
            type: "object"
            properties:
                <question_name>: { description: "The question to be asked", type: "string" }
                <question_name>: { description: "The question to be asked", type: "string" }
                <question_name>: { description: "The question to be asked", type: "string" }

----

This format ensures that the Snowpark model is able to convert to the JSON schema expected by the AI_EXTRACT function.

'''
link:ARCHITECTURE.adoc[← To Architecture] ||| link:SETUP.adoc[→ To Setup Guide]

'''


